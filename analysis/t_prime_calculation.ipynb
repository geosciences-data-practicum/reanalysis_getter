{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-prime and T-ref calculation\n",
    "\n",
    "This notebook will guide you through the processing of $ T_{ref} $ and $ T_{p} $ on both reanalysis and CIMP6 models. The process relies heavily on Dask `job-queue` and uses all the power of RCCs Midway to parallelize the code and get fast calculations. Be mindful that to reproduce this code you need to correctly configure `job-queue` by changing the `jobqueue.yaml` file (usually is in this path: in `$HOME/.config/dask/`). \n",
    "\n",
    "A small example of this configuration file is this one: \n",
    "\n",
    "```yaml\n",
    "jobqueue:\n",
    "  slurm:\n",
    "    name: dask-worker\n",
    "\n",
    "    # Dask worker options\n",
    "    cores: 28                  # Total number of cores per job\n",
    "    memory: '64GB'             # Total amount of memory per job\n",
    "    processes: 1               # Number of Python processes per job\n",
    "    n_workers: 0\n",
    "    nanny: false\n",
    "    job_extra:\n",
    "        - '--account=geos39650'\n",
    "        - '--output=dask_worker.out'\n",
    "        - '--error=dask_worker.err'\n",
    "\n",
    "    interface: ib0\n",
    "    local-directory: $SCRATCH$ \n",
    "    queue: 'broadwl'\n",
    "    walltime: '00:10:00'\n",
    "```\n",
    "\n",
    "Here, we're requesting 28 cores and 20 GB of RAM memory per job, this conincides with the average size of nodes in the `broadwl` partition. Every task we create will be pushed to each node! The number of requested nodes is dynamic, and can be either be user-defined or by-demand using the `cluster`. We will see how this works later! \n",
    "\n",
    "\n",
    "### Scheduler cool visuals\n",
    "\n",
    "Dask `job-queue` comes with a powerful shceduler visualizer that gives the user some hints about the job progress and efficiency of the cluster (in escence, Dask is actually creating its own cluster and submitting dedicated dask operations to it). The sheduler runs by default in the port 8484, and unless used, it can be accessed using from `https://localhost:8787`. But not so fast! This is running in the login node (if you're running this from the login node), so you need to run a `ssh` tunnel for that: `ssh -N -L 8787:<client_ip>:8787 ivanhigueram@midway.rcc.uchicago.edu`. Where `<client_ip>` is the IP address returned by the `Client` object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the libraries we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "\n",
    "from methods import (t_prime_calculation, \n",
    "                     dask_data_to_xarray,\n",
    "                     area_calculation_real_area,\n",
    "                     dists_of_lat_eff,\n",
    "                     temp_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up cluster\n",
    "As discussed earlier, we need to load our cluster configuration stored in the `jobqueue.yaml` configuration file. We can print the job request by running `cluster.job_script()`. Here we need two parts. First, we need a cluster object with all the parameters to pass to the Slurm manager. Second, we need a client that will be use by `xarray` and `dask` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env bash\n",
      "\n",
      "#SBATCH -J dask-worker\n",
      "#SBATCH -p broadwl\n",
      "#SBATCH -n 1\n",
      "#SBATCH --cpus-per-task=4\n",
      "#SBATCH --mem=19G\n",
      "#SBATCH -t 00:20:00\n",
      "#SBATCH --account=geos39650\n",
      "#SBATCH --output=dask_worker.out\n",
      "#SBATCH --error=dask_worker.err\n",
      "\n",
      "/scratch/midway2/ivanhigueram/reanalysis_env/bin/python -m distributed.cli.dask_worker tcp://172.25.220.71:48162 --nthreads 4 --memory-limit 20.00GB --name name --no-nanny --death-timeout 60 --local-directory $SCRATCH --interface ib0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cluster = SLURMCluster(nanny=False)\n",
    "print(cluster.job_script())\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, we will request the above computing power everytime we decide to scale our `client` object. By default, our client will have 0 workers, this to avoid requesting for un-used services and to have total control over the computing requests. The method `scale` allows to scale computation in a simple way. By default, any positive integer passed to `scale` will request that equivalent number of workers. We can request less resources than a complete node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's no rule-of-thumb in deciding how to decide the number of clusters. All depends on the type of job you're running\n",
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://172.25.220.71:48162</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.25.220.71:8787/status' target='_blank'>http://172.25.220.71:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://172.25.220.71:48162' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation on different climate products \n",
    "\n",
    "**WARNING**: System administrators do not like users running heavy computations in cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.upload_file('methods.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analysis with ERA-5 Reanalysis data\n",
    "\n",
    "Using the `xarray` library, let's analyze the reanalysis product. We have a daily file of winter data in a daily resolution: `data/processed_winters/df_lat_20_1D.nc` [This file was generated with our code in `src/analyzer.py`]. \n",
    "\n",
    "For this processing we will execute everything inside the `calculate_t_prime` function and will let `job-queue` to decide how manyt workers between 0 and 10 it needs to do the job (usually takes the maximum). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def calculate_t_prime(path_to_raw_file,\n",
    "                      path_to_save,\n",
    "                      start_year=1995,\n",
    "                      end_year=2020,\n",
    "                      size_year_range=5,\n",
    "                      gcm_hack=False,\n",
    "                      outputs=['t_ref', 't_prime'],\n",
    "                      **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate t_prime for the user-defined path and output a NetCDF file with\n",
    "    the processed data\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'Initializing t prime calculation')\n",
    "    \n",
    "    for year in range(start_year, end_year, size_year_range):\n",
    "        # Define time ranges \n",
    "        start_year = datetime(year, 12, 1).strftime('%Y-%m-%d')\n",
    "        end_year = datetime(year + size_year_range, 3, 1).strftime('%Y-%m-%d')\n",
    "\n",
    "        print(f\"Start processing -- {start_year} to {end_year}\")\n",
    "        xarray_file = xr.open_dataset(path_to_raw_file,\n",
    "                                      chunks={'time': 1})\n",
    "      \n",
    "        \n",
    "        if gcm_hack:\n",
    "            model='gcm'\n",
    "            xarray_file = xarray_file.isel(member_id=0, nbnd=0)\n",
    "    \n",
    "            datetime_index = xarray_file.indexes['time'].to_datetimeindex()\n",
    "            xarray_file['time'] = datetime_index\n",
    "            \n",
    "            xarray_file = xarray_file.sel(time=slice(start_year, end_year))\n",
    "            t_df = xarray_file.to_dask_dataframe(dim_order=['time', 'lat', 'lon'])\n",
    "            t_df_renamed = t_df.rename(columns={\n",
    "                    'lat': 'latitude',\n",
    "                    'lon': 'longitude',\n",
    "                    'tas': 't2m'\n",
    "                })\n",
    "            t_df = t_df_renamed[['time', 'latitude', 'longitude', 't2m']]  \n",
    "        else:\n",
    "            model='reanalysis'\n",
    "            xarray_file_year_range = xarray_file.sel(time=slice(start_year, end_year))\n",
    "            t_df = xarray_file_year_range.to_dask_dataframe(dim_order=['time', 'latitude', 'longitude'])\n",
    "\n",
    "        # Initialize t_prime calculation using dask DataFrame\n",
    "        test_ultimate = t_prime_calculation(t_df,\n",
    "                                            grid_lat=kwargs['grid_lat'],\n",
    "                                            grid_lon=kwargs['grid_lon'],\n",
    "                                            resample_time=False,\n",
    "                                            build_buckets=True,\n",
    "                                            cut_interval=2\n",
    "                                           )\n",
    "\n",
    "        # Save results to NetCDF\n",
    "        for out in outputs:\n",
    "\n",
    "            print(f'Saving {out} file to netcdf')\n",
    "            t_ref_test = dask_data_to_xarray(df=test_ultimate,\n",
    "                                             dims=['time', 'latitude', 'longitude'],\n",
    "                                             target_variable=out)\n",
    "            path_save = os.path.join(path_to_save, f'{out}_gcm_{start_year}_{end_year}.nc4')\n",
    "            t_ref_test.to_netcdf(path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send parallel jobs using `cluster.adapt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.adapt(minimum=1, maximum=10)\n",
    "cluster.scale(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_t_prime(path_to_raw_file='/project2/geos39650/jet_stream/data/processed_winters/df_lat_20_1D.nc',\n",
    "                  path_to_save='/project2/geos39650/jet_stream/data/model_output/',\n",
    "                  outputs=['t_prime', 't_ref'],\n",
    "                  grid_lat=0.25,\n",
    "                  grid_lon=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analysis with CIMP6 climate projection data\n",
    "\n",
    "Just as we did with the ERA-5 data, we will load the processed winter data from the projection data: `data/processed_winters/ScenarioMIP_NCAR_CESM2-WACCM_ssp585_day.nc4` [This file was generated with our code in `src/analyzer.py`]. \n",
    "\n",
    "For this processing we will execute everything inside the `calculate_t_prime` function and will let `job-queue` to decide how manyt workers between 0 and 10 it needs to do the job (usually takes the maximum). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.adapt(minimum=30, maximum=40)\n",
    "cluster.scale(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing t prime calculation\n",
      "Start processing -- 2035-12-01 to 2045-03-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/midway2/ivanhigueram/reanalysis_env/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving t_ref file to netcdf\n",
      "Saving t_prime file to netcdf\n"
     ]
    }
   ],
   "source": [
    "calculate_t_prime(path_to_raw_file='/project2/geos39650/jet_stream/data/processed_winters/ScenarioMIP_NCAR_CESM2-WACCM_ssp585_day.nc4',\n",
    "                  path_to_save='/project2/geos39650/jet_stream/data/model_output/',\n",
    "                  grid_lat=0.9,\n",
    "                  grid_lon=1.25,\n",
    "                  start_year=2035,\n",
    "                  end_year=2101,\n",
    "                  size_year_range=10,\n",
    "                  gcm_hack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
